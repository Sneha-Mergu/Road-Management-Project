{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6982383",
   "metadata": {},
   "source": [
    "#Scene Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4dbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "video_path = r\"D:\\Road Management\\trim_videos\\Bhingar.mp4\"\n",
    "output_dir = r\"C:\\Users\\krish\\Documents\\a_aRMP\\newframes\\ar\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "hist_thresh = 0.6  \n",
    "frame_interval = 5 \n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "prev_hist = None\n",
    "frame_count = 0\n",
    "saved_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if frame_count % frame_interval == 0:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "        hist = cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "        if prev_hist is None:\n",
    "            prev_hist = hist\n",
    "            cv2.imwrite(f\"{output_dir}/frame_{saved_count:03d}.jpg\", frame)\n",
    "            saved_count += 1\n",
    "        else:\n",
    "            diff = cv2.compareHist(prev_hist, hist, cv2.HISTCMP_CORREL)\n",
    "            if diff < hist_thresh:\n",
    "                cv2.imwrite(f\"{output_dir}/frame_{saved_count:03d}.jpg\", frame)\n",
    "                saved_count += 1\n",
    "                prev_hist = hist\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "print(f\"Done! Saved {saved_count} key frames.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4263ae7f",
   "metadata": {},
   "source": [
    "#COCO to YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a83a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "coco_path = r\"D:\\Road Management\\data_for_label\\labels.json\"  \n",
    "images_dir = r\"D:\\Road Management\\data_for_label\\images\"       \n",
    "output_dir = r\"D:\\Road Management\\data_for_label\\labels\"          \n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(coco_path, 'r') as f:\n",
    "    coco = json.load(f)\n",
    "\n",
    "image_map = {img[\"id\"]: img for img in coco[\"images\"]}\n",
    "\n",
    "for ann in coco[\"annotations\"]:\n",
    "    image_id = ann[\"image_id\"]\n",
    "    image_info = image_map[image_id]\n",
    "\n",
    "    file_stem = Path(image_info[\"file_name\"]).stem\n",
    "    width = image_info[\"width\"]\n",
    "    height = image_info[\"height\"]\n",
    "\n",
    "    x, y, w, h = ann[\"bbox\"]\n",
    "    class_id = ann[\"category_id\"] - 1 \n",
    "\n",
    "    x_center = (x + w / 2) / width\n",
    "    y_center = (y + h / 2) / height\n",
    "    w /= width\n",
    "    h /= height\n",
    "\n",
    "    label_path = os.path.join(output_dir, f\"{file_stem}.txt\")\n",
    "    with open(label_path, 'a') as f:\n",
    "        f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb40bf4",
   "metadata": {},
   "source": [
    "#model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eedd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U ultralytics\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "results = model.train(\n",
    "    data=r\"C:\\Users\\krish\\Documents\\a_aRMP\\Pr\\data.yaml\",\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    cache=True,\n",
    "    project='road',\n",
    "    name='yolov8_coco',\n",
    "    val=True\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc4d427",
   "metadata": {},
   "source": [
    "#Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a18662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(r\"D:\\Road Management\\data_for_label\\road\\yolov8m_coco\\weights\\best.pt\")\n",
    "\n",
    "results = model.predict(source=r\"D:\\Road Management\\for_prediction\", save=True, save_txt=True, imgsz=640, conf=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30f529a",
   "metadata": {},
   "source": [
    "#Extracting GPS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14de4574",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytesseract opencv-python\n",
    "\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "import cv2\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Setup\n",
    "folder_path = r\"D:\\Road Management\\A_Project\\labelled\\images\"\n",
    "output_csv = r\"a_try\\gps_timestamp_data1.csv\"\n",
    "data = [] \n",
    "\n",
    "def numerical_sort(value):\n",
    "    numbers = re.findall(r'\\d+', value)\n",
    "    return int(numbers[0]) if numbers else -1\n",
    "\n",
    "files = [f for f in os.listdir(folder_path) if f.lower().endswith('.jpg')]\n",
    "files.sort(key=numerical_sort)\n",
    "\n",
    "for filename in files:\n",
    "    img_path = os.path.join(folder_path, filename)\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    if img is None:\n",
    "        print(f\"⚠️ Could not read image: {filename}\")\n",
    "        continue\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    pil_img = Image.fromarray(thresh)\n",
    "    extracted_text = pytesseract.image_to_string(pil_img)\n",
    "    extracted_text = re.sub(r'[^\\x00-\\x7F]+', ' ', extracted_text)\n",
    "\n",
    "    lat_match = re.search(r'Lat(?:itude)?\\s*[:\\-]?\\s*([-+]?\\d{1,3}\\.\\d+)', extracted_text, re.IGNORECASE)\n",
    "    lon_match = re.search(r'Long(?:itude)?\\s*[:\\-]?\\s*([-+]?\\d{1,3}\\.\\d+)', extracted_text, re.IGNORECASE) or \\\n",
    "                re.search(r'Long\\s+([-+]?\\d{1,3}\\.\\d+)', extracted_text, re.IGNORECASE)\n",
    "    time_match = re.search(r'(\\d{2}[/\\-| ]\\d{2}[/\\-| ]\\d{2,4})\\s*(\\d{2}:\\d{2}:\\d{2})\\s*([APap][Mm])', extracted_text)\n",
    "\n",
    "    latitude = lat_match.group(1) if lat_match else \"Not found\"\n",
    "    longitude = lon_match.group(1).replace('°', '') if lon_match else \"Not found\"\n",
    "    timestamp = f\"{time_match.group(1).replace('|', '/').replace('-', '/')} {time_match.group(2)} {time_match.group(3).upper()}\" \\\n",
    "        if time_match else \"Not found\"\n",
    "\n",
    "    data.append({\n",
    "        \"Image\": filename,\n",
    "        \"Latitude\": latitude,\n",
    "        \"Longitude\": longitude,\n",
    "        \"Timestamp\": timestamp\n",
    "    })\n",
    "\n",
    "    print(f\"{filename} → Lat: {latitude}, Lon: {longitude}, Time: {timestamp}\")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"\\n✅ Data saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb25389d",
   "metadata": {},
   "source": [
    "#separating frames based on Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a008d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn geopy\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import re\n",
    "\n",
    "csv_path = r\"D:\\Road Management\\A_Project\\gps_timestamp_data.csv\"\n",
    "image_folder = r\"D:\\Road Management\\A_Project\\labelled\\images\"\n",
    "output_base = r\"C:\\Users\\krish\\Documents\\a_aRMP\\a_try\\location_wise_frames\"\n",
    "distance_threshold_meters = 1000\n",
    "min_samples_cluster = 1\n",
    "output_csv = r\"C:\\Users\\krish\\Documents\\a_aRMP\\a_try\\cluster.csv\"\n",
    "\n",
    "def clean_folder_name(name):\n",
    "    name = re.sub(r'[\\\\/:\"*?<>|]+', '', name)\n",
    "    name = name.replace(' ', '_')\n",
    "    return name[:100].strip()\n",
    "\n",
    "def get_location_name(geolocator, lat, lon):\n",
    "    try:\n",
    "        location = geolocator.reverse((lat, lon), language='en')\n",
    "        if location and location.raw.get('address'):\n",
    "            address = location.raw['address']\n",
    "            for key in ['road', 'suburb', 'neighbourhood', 'village', 'town', 'city', 'county', 'state']:\n",
    "                if key in address:\n",
    "                    return address[key]\n",
    "        return \"Unknown_Location\"\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Reverse geocoding error at ({lat},{lon}): {e}\")\n",
    "        return \"Unknown_Location\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"⏳ Loading data...\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    df = df[df['Latitude'].apply(lambda x: str(x).lower() != 'not found')]\n",
    "    df = df[df['Longitude'].apply(lambda x: str(x).lower() != 'not found')]\n",
    "    df['Latitude'] = df['Latitude'].astype(float)\n",
    "    df['Longitude'] = df['Longitude'].astype(float)\n",
    "\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce', dayfirst=True)\n",
    "    missing_ts = df['Timestamp'].isna().sum()\n",
    "    print(f\"⚠️ Missing timestamps in {missing_ts} rows.\")\n",
    "\n",
    "    df['Sort_Key'] = df['Timestamp'].astype(str) + \"_\" + df['Image']\n",
    "    df = df.sort_values(by='Sort_Key')\n",
    "\n",
    "    coords = df[['Latitude', 'Longitude']].to_numpy()\n",
    "    radians_coords = np.radians(coords)\n",
    "    kms_per_radian = 6371.0088\n",
    "    epsilon = distance_threshold_meters / 1000.0 / kms_per_radian\n",
    "\n",
    "    print(f\"⏳ Clustering with DBSCAN (eps={epsilon:.6f})...\")\n",
    "    db = DBSCAN(eps=epsilon, min_samples=min_samples_cluster, algorithm='ball_tree', metric='haversine')\n",
    "    cluster_labels = db.fit_predict(radians_coords)\n",
    "    df['Group'] = cluster_labels\n",
    "    n_clusters = len(set(cluster_labels))\n",
    "    print(f\"✅ Found {n_clusters} groups.\")\n",
    "\n",
    "    geolocator = Nominatim(user_agent=\"gps_grouping_app\")\n",
    "    geocode = RateLimiter(geolocator.reverse, min_delay_seconds=1)\n",
    "\n",
    "    cluster_info = {\n",
    "        'Group_ID': [],\n",
    "        'Folder_Name': [],\n",
    "        'Start_Coordinates': [],\n",
    "        'End_Coordinates': [],\n",
    "        'Start_Location': [],\n",
    "        'End_Location': [],\n",
    "        'Number_of_Images': []\n",
    "    }\n",
    "\n",
    "    group_folder_map = {}\n",
    "    location_count = {}\n",
    "\n",
    "    for group_id in sorted(set(cluster_labels)):\n",
    "        group_df = df[df['Group'] == group_id].sort_values(by='Sort_Key')\n",
    "        group_points = group_df[['Latitude', 'Longitude']]\n",
    "        group_images = group_df['Image']\n",
    "\n",
    "        start_lat, start_lon = group_points.iloc[0]['Latitude'], group_points.iloc[0]['Longitude']\n",
    "        end_lat, end_lon = group_points.iloc[-1]['Latitude'], group_points.iloc[-1]['Longitude']\n",
    "\n",
    "        start_location = get_location_name(geolocator, start_lat, start_lon)\n",
    "        end_location = get_location_name(geolocator, end_lat, end_lon)\n",
    "\n",
    "        base_name = clean_folder_name(start_location)\n",
    "        location_count[base_name] = location_count.get(base_name, 0) + 1\n",
    "        folder_name = f\"{base_name}_{location_count[base_name]}\"\n",
    "\n",
    "        group_folder_map[group_id] = folder_name\n",
    "\n",
    "        print(f\"Group {group_id} -> Folder: {folder_name} | Start: ({start_lat}, {start_lon}) | End: ({end_lat}, {end_lon})\")\n",
    "\n",
    "        cluster_info['Group_ID'].append(group_id)\n",
    "        cluster_info['Folder_Name'].append(folder_name)\n",
    "        cluster_info['Start_Coordinates'].append(f\"{start_lat}, {start_lon}\")\n",
    "        cluster_info['End_Coordinates'].append(f\"{end_lat}, {end_lon}\")\n",
    "        cluster_info['Start_Location'].append(start_location)\n",
    "        cluster_info['End_Location'].append(end_location)\n",
    "        cluster_info['Number_of_Images'].append(len(group_images))\n",
    "\n",
    "    cluster_df = pd.DataFrame(cluster_info)\n",
    "    cluster_df.to_csv(output_csv, index=False)\n",
    "    print(f\"✅ Cluster info saved to {output_csv}\")\n",
    "\n",
    "    print(f\"⏳ Copying images to folders...\")\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "    for group_id, folder_name in group_folder_map.items():\n",
    "        group_folder_path = os.path.join(output_base, folder_name)\n",
    "        os.makedirs(group_folder_path, exist_ok=True)\n",
    "\n",
    "        group_images = df[df['Group'] == group_id]['Image']\n",
    "        for img in group_images:\n",
    "            src = os.path.join(image_folder, img)\n",
    "            dst = os.path.join(group_folder_path, img)\n",
    "            if os.path.exists(src):\n",
    "                shutil.copy2(src, dst)\n",
    "            else:\n",
    "                print(f\"⚠️ File not found: {src}\")\n",
    "\n",
    "    print(\"✅ All done!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2199fc9d",
   "metadata": {},
   "source": [
    "#Sepating in different folders based on label type with annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f67964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import Counter\n",
    "\n",
    "annotation_folder = r\"D:\\Road Management\\A_Project\\labelled\\labels\" \n",
    "location_base_folder = r\"C:\\Users\\krish\\Documents\\a_aRMP\\a_try\\location_wise_frames\" \n",
    "priority_labels = [\"surface damage\", \"pothole\", \"cracks\", \"manhole\"]\n",
    "\n",
    "category_map = {\n",
    "    0: \"pothole\", 1: \"manhole\", 2: \"surface damage\", 3: \"cracks\",\n",
    "    4: \"edge line\", 5: \"lane mark\", 6: \"lane divider\", 7: \"zebra crossing\",\n",
    "    8: \"speed breakers\", 9: \"no entry zone\", 10: \"warning lines\",\n",
    "    11: \"patches\", 12: \"sign board\"\n",
    "}\n",
    "\n",
    "def categorize_labels_in_locations():\n",
    "    for location_folder_name in os.listdir(location_base_folder):\n",
    "        location_folder_path = os.path.join(location_base_folder, location_folder_name)\n",
    "        if not os.path.isdir(location_folder_path):\n",
    "            continue\n",
    "\n",
    "        images = [f for f in os.listdir(location_folder_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "        for image_name in images:\n",
    "            base_name = os.path.splitext(image_name)[0]\n",
    "            label_name = base_name + \".txt\"\n",
    "            label_path = os.path.join(annotation_folder, label_name)\n",
    "            image_path = os.path.join(location_folder_path, image_name)\n",
    "\n",
    "            if not os.path.exists(label_path):\n",
    "                print(f\"Label file missing for {image_name}\")\n",
    "                continue\n",
    "\n",
    "            label_counts = Counter()\n",
    "            box_data = []\n",
    "            with open(label_path, \"r\") as f:\n",
    "                for line in f.readlines():\n",
    "                    values = line.split()\n",
    "                    class_id = int(values[0])\n",
    "                    label_str = category_map.get(class_id, \"unknown\")\n",
    "                    label_counts[label_str] += 1\n",
    "                    box_data.append((label_str, float(values[1]), float(values[2]), float(values[3]), float(values[4])))\n",
    "\n",
    "            if not label_counts:\n",
    "                print(f\"No labels found in {label_name}\")\n",
    "                continue\n",
    "\n",
    "            most_common_labels = label_counts.most_common()\n",
    "            top_label = most_common_labels[0][0]\n",
    "            tied_labels = [label for label, count in most_common_labels if count == most_common_labels[0][1]]\n",
    "            \n",
    "            prioritized = [label for label in tied_labels if label in priority_labels]\n",
    "            if prioritized:\n",
    "                top_label = prioritized[0]\n",
    "            else:\n",
    "                max_area = 0\n",
    "                for label, x_center, y_center, width, height in box_data:\n",
    "                    if label in tied_labels and x_center < 0.5:\n",
    "                        area = width * height\n",
    "                        if area > max_area:\n",
    "                            max_area = area\n",
    "                            top_label = label\n",
    "\n",
    "            label_folder_path = os.path.join(location_folder_path, top_label)\n",
    "            label_subfolder = os.path.join(label_folder_path, \"labels\")\n",
    "            image_subfolder = os.path.join(label_folder_path, \"images\")\n",
    "            os.makedirs(label_subfolder, exist_ok=True)\n",
    "            os.makedirs(image_subfolder, exist_ok=True)\n",
    "\n",
    "            shutil.copy(label_path, os.path.join(label_subfolder, label_name))\n",
    "            print(f\"Copied {label_name} to {label_subfolder}\")\n",
    "\n",
    "            shutil.move(image_path, os.path.join(image_subfolder, image_name))\n",
    "            print(f\"Moved {image_name} to {image_subfolder}\")\n",
    "\n",
    "categorize_labels_in_locations()\n",
    "print(\"✅ Images moved and label files copied into separate folders inside label-wise directories.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a863fad",
   "metadata": {},
   "source": [
    "#total summary in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613ca148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "csv_path = r\"C:\\Users\\krish\\Documents\\a_aRMP\\a_try\\cluster.csv\" \n",
    "base_folder = r\"C:\\Users\\krish\\Documents\\a_aRMP\\a_try\\location_wise_frames\"  \n",
    "category_map = {\n",
    "    0: \"pothole\", 1: \"manhole\", 2: \"surface damage\", 3: \"cracks\",\n",
    "    4: \"edge line\", 5: \"lane mark\", 6: \"lane divider\", 7: \"zebra crossing\",\n",
    "    8: \"speed breakers\", 9: \"no entry zone\", 10: \"warning lines\",\n",
    "    11: \"patches\", 12: \"sign board\"\n",
    "}\n",
    "\n",
    "label_names = list(category_map.values())\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "for label in label_names:\n",
    "    df[label] = 0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    folder_name = row[\"Folder_Name\"]\n",
    "    folder_path = os.path.join(base_folder, folder_name)\n",
    "    \n",
    "    label_counter = Counter()\n",
    "    \n",
    "    if os.path.exists(folder_path):\n",
    "        for label_folder in os.listdir(folder_path):\n",
    "            label_folder_path = os.path.join(folder_path, label_folder, \"labels\")\n",
    "            if not os.path.isdir(label_folder_path):\n",
    "                continue\n",
    "            \n",
    "            for txt_file in os.listdir(label_folder_path):\n",
    "                if txt_file.endswith(\".txt\"):\n",
    "                    txt_path = os.path.join(label_folder_path, txt_file)\n",
    "                    with open(txt_path, \"r\") as f:\n",
    "                        for line in f:\n",
    "                            parts = line.strip().split()\n",
    "                            if not parts:\n",
    "                                continue\n",
    "                            class_id = int(parts[0])\n",
    "                            label_str = category_map.get(class_id, \"unknown\")\n",
    "                            label_counter[label_str] += 1\n",
    "\n",
    "        for label in label_names:\n",
    "            df.at[idx, label] = label_counter[label]\n",
    "\n",
    "output_csv_path = r\"C:\\Users\\krish\\Documents\\a_aRMP\\a_try\\summary.csv\"\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(\"✅ Updated cluster summary saved with label-wise counts.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
